{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example\n",
    "\n",
    "This example demonstrates the process of loading dataset, training, evaluation and prediction, using an expamplary dataset. The dataset contains 500 graphene structures that are generated using Rebo potential. The code has been run with Tensorflow 2.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atomdnn\n",
    "\n",
    "# 'float32' is used for reading data and train by default, one can set data_type to 'float64' here\n",
    "atomdnn.data_type = 'float64'\n",
    "\n",
    "# force and stress are evaluated by default, \n",
    "# if one only need to compute potential energy, then set compute_force to false\n",
    "atomdnn.compute_force = True\n",
    "\n",
    "# default value is for converting ev/A^3 to GPa\n",
    "# note that: the predicted positive stress means tension and negative stress means compression\n",
    "stress_unit_convert = 160.2176 \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from atomdnn import data\n",
    "from atomdnn import network\n",
    "from atomdnn.data import Data\n",
    "from atomdnn.data import *\n",
    "from atomdnn.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 19:38:30.072748: W tensorflow/stream_executor/platform/default/dso_loader.cc:65] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2021-10-18 19:38:30.072780: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-18 19:38:30.072833: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n"
     ]
    }
   ],
   "source": [
    "# load tensorflow dataset, for Tensorflow version lower than 2.6, need to specify element_spec.\n",
    "# The process of reading data and creating dataset is discussed in 'Data pipeline' section.\n",
    "\n",
    "dataset = tf.data.experimental.load('example_tfdataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning data: 350 images\n",
      "Validation data: 100 images\n",
      "Test data: 50 images\n"
     ]
    }
   ],
   "source": [
    "# split the data to training, validation and testing sets\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = split_dataset(dataset,0.7,0.2,0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the network\n",
    "# See section 'Training' for detailed description on Network object.\n",
    "\n",
    "elements = ['C']\n",
    "act_fun = 'relu' # activation function\n",
    "nfp = get_fingerprints_num(dataset) # number of fingerprints (or descriptors)\n",
    "arch = [30,30] # NN layers\n",
    "\n",
    "model = Network(elements = elements,\\\n",
    "                num_fingerprints = nfp,\\\n",
    "                arch = arch,\\\n",
    "                activation_function = act_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 19:38:30.138312: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forces are used for training.\n",
      "Stresses are used for training.\n",
      "Scaling factors are computed using training dataset.\n",
      "Training dataset are standardized.\n",
      "Validation dataset are standardized.\n",
      "Training dataset will be shuffled during training.\n",
      "\n",
      "===> Epoch 1/30 - 0.823s/epoch\n",
      "     training_loss    - pe_loss: 329.196 - force_loss: 1186.271 - stress_loss: 51101.325 - total_loss: 6625.600\n",
      "     validation_loss  - pe_loss: 71.290 - force_loss: 593.548 - stress_loss: 25557.508 - total_loss: 3220.589\n",
      "\n",
      "===> Epoch 2/30 - 0.827s/epoch\n",
      "     training_loss    - pe_loss: 64.465 - force_loss: 589.883 - stress_loss: 21025.056 - total_loss: 2756.854\n",
      "     validation_loss  - pe_loss: 44.031 - force_loss: 524.868 - stress_loss: 20366.036 - total_loss: 2605.503\n",
      "\n",
      "===> Epoch 3/30 - 0.800s/epoch\n",
      "     training_loss    - pe_loss: 40.991 - force_loss: 415.016 - stress_loss: 14697.165 - total_loss: 1925.723\n",
      "     validation_loss  - pe_loss: 19.335 - force_loss: 370.859 - stress_loss: 15252.499 - total_loss: 1915.444\n",
      "\n",
      "===> Epoch 4/30 - 0.834s/epoch\n",
      "     training_loss    - pe_loss: 26.506 - force_loss: 292.901 - stress_loss: 12483.164 - total_loss: 1567.723\n",
      "     validation_loss  - pe_loss: 16.917 - force_loss: 280.031 - stress_loss: 10499.152 - total_loss: 1346.864\n",
      "\n",
      "===> Epoch 5/30 - 0.828s/epoch\n",
      "     training_loss    - pe_loss: 16.912 - force_loss: 236.864 - stress_loss: 8681.934 - total_loss: 1121.969\n",
      "     validation_loss  - pe_loss: 18.306 - force_loss: 222.935 - stress_loss: 7149.523 - total_loss: 956.193\n",
      "\n",
      "===> Epoch 6/30 - 0.846s/epoch\n",
      "     training_loss    - pe_loss: 17.252 - force_loss: 215.184 - stress_loss: 7222.672 - total_loss: 954.703\n",
      "     validation_loss  - pe_loss: 14.455 - force_loss: 206.465 - stress_loss: 6982.005 - total_loss: 919.121\n",
      "\n",
      "===> Epoch 7/30 - 0.799s/epoch\n",
      "     training_loss    - pe_loss: 19.243 - force_loss: 206.185 - stress_loss: 5448.862 - total_loss: 770.314\n",
      "     validation_loss  - pe_loss: 19.929 - force_loss: 203.600 - stress_loss: 5608.156 - total_loss: 784.344\n",
      "\n",
      "===> Epoch 8/30 - 0.823s/epoch\n",
      "     training_loss    - pe_loss: 14.316 - force_loss: 181.696 - stress_loss: 4453.825 - total_loss: 641.394\n",
      "     validation_loss  - pe_loss: 8.803 - force_loss: 164.327 - stress_loss: 4637.299 - total_loss: 636.860\n",
      "\n",
      "===> Epoch 9/30 - 0.757s/epoch\n",
      "     training_loss    - pe_loss: 10.285 - force_loss: 159.417 - stress_loss: 4123.353 - total_loss: 582.037\n",
      "     validation_loss  - pe_loss: 15.460 - force_loss: 153.061 - stress_loss: 3475.252 - total_loss: 516.046\n",
      "\n",
      "===> Epoch 10/30 - 0.828s/epoch\n",
      "     training_loss    - pe_loss: 8.578 - force_loss: 131.914 - stress_loss: 2841.170 - total_loss: 424.609\n",
      "     validation_loss  - pe_loss: 6.047 - force_loss: 110.113 - stress_loss: 2583.763 - total_loss: 374.536\n",
      "\n",
      "===> Epoch 11/30 - 0.832s/epoch\n",
      "     training_loss    - pe_loss: 8.459 - force_loss: 111.855 - stress_loss: 2510.459 - total_loss: 371.360\n",
      "     validation_loss  - pe_loss: 6.739 - force_loss: 97.513 - stress_loss: 2557.079 - total_loss: 359.960\n",
      "\n",
      "===> Epoch 12/30 - 0.824s/epoch\n",
      "     training_loss    - pe_loss: 6.686 - force_loss: 96.138 - stress_loss: 2256.936 - total_loss: 328.518\n",
      "     validation_loss  - pe_loss: 8.103 - force_loss: 84.706 - stress_loss: 1607.031 - total_loss: 253.513\n",
      "\n",
      "===> Epoch 13/30 - 0.802s/epoch\n",
      "     training_loss    - pe_loss: 5.332 - force_loss: 83.776 - stress_loss: 1665.297 - total_loss: 255.638\n",
      "     validation_loss  - pe_loss: 7.424 - force_loss: 77.638 - stress_loss: 1477.467 - total_loss: 232.809\n",
      "\n",
      "===> Epoch 14/30 - 0.787s/epoch\n",
      "     training_loss    - pe_loss: 6.277 - force_loss: 66.451 - stress_loss: 1110.298 - total_loss: 183.758\n",
      "     validation_loss  - pe_loss: 5.271 - force_loss: 63.206 - stress_loss: 1013.482 - total_loss: 169.825\n",
      "\n",
      "===> Epoch 15/30 - 0.806s/epoch\n",
      "     training_loss    - pe_loss: 4.293 - force_loss: 59.219 - stress_loss: 820.057 - total_loss: 145.517\n",
      "     validation_loss  - pe_loss: 3.649 - force_loss: 58.749 - stress_loss: 696.462 - total_loss: 132.044\n",
      "\n",
      "===> Epoch 16/30 - 0.778s/epoch\n",
      "     training_loss    - pe_loss: 3.928 - force_loss: 55.018 - stress_loss: 553.755 - total_loss: 114.322\n",
      "     validation_loss  - pe_loss: 5.329 - force_loss: 56.482 - stress_loss: 557.332 - total_loss: 117.544\n",
      "\n",
      "===> Epoch 17/30 - 0.796s/epoch\n",
      "     training_loss    - pe_loss: 3.494 - force_loss: 49.556 - stress_loss: 410.958 - total_loss: 94.146\n",
      "     validation_loss  - pe_loss: 2.959 - force_loss: 44.978 - stress_loss: 306.428 - total_loss: 78.580\n",
      "\n",
      "===> Epoch 18/30 - 0.832s/epoch\n",
      "     training_loss    - pe_loss: 3.237 - force_loss: 42.961 - stress_loss: 358.929 - total_loss: 82.091\n",
      "     validation_loss  - pe_loss: 3.212 - force_loss: 41.907 - stress_loss: 222.606 - total_loss: 67.380\n",
      "\n",
      "===> Epoch 19/30 - 0.788s/epoch\n",
      "     training_loss    - pe_loss: 2.850 - force_loss: 39.862 - stress_loss: 264.062 - total_loss: 69.118\n",
      "     validation_loss  - pe_loss: 5.140 - force_loss: 38.938 - stress_loss: 293.775 - total_loss: 73.456\n",
      "\n",
      "===> Epoch 20/30 - 0.793s/epoch\n",
      "     training_loss    - pe_loss: 2.501 - force_loss: 36.337 - stress_loss: 241.441 - total_loss: 62.981\n",
      "     validation_loss  - pe_loss: 2.746 - force_loss: 34.924 - stress_loss: 182.217 - total_loss: 55.892\n",
      "\n",
      "===> Epoch 21/30 - 0.786s/epoch\n",
      "     training_loss    - pe_loss: 2.405 - force_loss: 32.611 - stress_loss: 200.839 - total_loss: 55.100\n",
      "     validation_loss  - pe_loss: 2.255 - force_loss: 30.684 - stress_loss: 188.417 - total_loss: 51.780\n",
      "\n",
      "===> Epoch 22/30 - 0.829s/epoch\n",
      "     training_loss    - pe_loss: 2.061 - force_loss: 29.514 - stress_loss: 109.054 - total_loss: 42.481\n",
      "     validation_loss  - pe_loss: 2.239 - force_loss: 30.190 - stress_loss: 52.662 - total_loss: 37.696\n",
      "\n",
      "===> Epoch 23/30 - 0.821s/epoch\n",
      "     training_loss    - pe_loss: 2.168 - force_loss: 28.087 - stress_loss: 109.374 - total_loss: 41.193\n",
      "     validation_loss  - pe_loss: 2.182 - force_loss: 26.509 - stress_loss: 131.025 - total_loss: 41.794\n",
      "\n",
      "===> Epoch 24/30 - 0.780s/epoch\n",
      "     training_loss    - pe_loss: 1.998 - force_loss: 26.025 - stress_loss: 129.514 - total_loss: 40.974\n",
      "     validation_loss  - pe_loss: 1.772 - force_loss: 25.651 - stress_loss: 130.407 - total_loss: 40.463\n",
      "\n",
      "===> Epoch 25/30 - 0.791s/epoch\n",
      "     training_loss    - pe_loss: 1.807 - force_loss: 24.448 - stress_loss: 115.513 - total_loss: 37.807\n",
      "     validation_loss  - pe_loss: 2.451 - force_loss: 25.453 - stress_loss: 111.290 - total_loss: 39.032\n",
      "\n",
      "===> Epoch 26/30 - 0.812s/epoch\n",
      "     training_loss    - pe_loss: 1.785 - force_loss: 23.627 - stress_loss: 119.524 - total_loss: 37.365\n",
      "     validation_loss  - pe_loss: 1.920 - force_loss: 23.038 - stress_loss: 147.967 - total_loss: 39.755\n",
      "\n",
      "===> Epoch 27/30 - 0.794s/epoch\n",
      "     training_loss    - pe_loss: 1.782 - force_loss: 21.853 - stress_loss: 148.094 - total_loss: 38.445\n",
      "     validation_loss  - pe_loss: 2.346 - force_loss: 24.197 - stress_loss: 66.409 - total_loss: 33.184\n",
      "\n",
      "===> Epoch 28/30 - 0.802s/epoch\n",
      "     training_loss    - pe_loss: 1.503 - force_loss: 21.766 - stress_loss: 87.770 - total_loss: 32.047\n",
      "     validation_loss  - pe_loss: 1.840 - force_loss: 21.265 - stress_loss: 54.426 - total_loss: 28.548\n",
      "\n",
      "===> Epoch 29/30 - 0.834s/epoch\n",
      "     training_loss    - pe_loss: 1.565 - force_loss: 20.168 - stress_loss: 56.887 - total_loss: 27.422\n",
      "     validation_loss  - pe_loss: 2.937 - force_loss: 19.218 - stress_loss: 98.842 - total_loss: 32.040\n",
      "\n",
      "===> Epoch 30/30 - 0.791s/epoch\n",
      "     training_loss    - pe_loss: 1.837 - force_loss: 19.309 - stress_loss: 112.887 - total_loss: 32.434\n",
      "     validation_loss  - pe_loss: 2.805 - force_loss: 18.164 - stress_loss: 51.657 - total_loss: 26.134\n",
      "\n",
      "End of training, elapsed time:  00:00:24\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "\n",
    "opt = 'Adam' # optimizer\n",
    "loss_fun = 'rmse' # loss function\n",
    "scaling = 'std' # scaling the traning data with standardization\n",
    "lr = 0.02 # learning rate\n",
    "loss_weights = {'pe' : 1, 'force' : 1, 'stress': 0.1} # the weights in loss function\n",
    "\n",
    "model.train(train_dataset, val_dataset, \\\n",
    "            optimizer=opt, \\\n",
    "            loss_fun = loss_fun, \\\n",
    "            batch_size=30, \\\n",
    "            lr=lr, \\\n",
    "            epochs=30, \\\n",
    "            scaling=scaling, \\\n",
    "            loss_weights=loss_weights, \\\n",
    "            compute_all_loss=True, \\\n",
    "            shuffle=True, \\\n",
    "            append_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss is:\n",
      "        pe_loss:       1.0684e+00\n",
      "     force_loss:       6.7686e+00\n",
      "    stress_loss:       4.2568e+01\n",
      "     total_loss:       1.2094e+01\n",
      "The total loss is computed using the loss weights - pe: 1.00 - force: 1.00 - stress: 0.10\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using the first 5 data in test dataset\n",
    "\n",
    "model.evaluate(test_dataset.take(5),return_prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pe': array([-28.308469  , -30.70238078, -28.37588111, -28.59157203,\n",
       "        -27.23017633]),\n",
       " 'force': array([[[ -4.87540508,  16.20537386,  51.23653551],\n",
       "         [  9.31678774,  -5.65669885, -31.3836977 ],\n",
       "         [-13.68639882,   1.94890128, -20.72748745],\n",
       "         [  9.24501616, -12.49757641,   0.87464961]],\n",
       " \n",
       "        [[ 29.56516981,   5.88600637,  13.2147016 ],\n",
       "         [ 19.65903927,  -3.42711633, -22.04439536],\n",
       "         [-24.48530241,  -4.51321415,  14.96612353],\n",
       "         [-24.73890695,   2.05432393,  -6.13642973]],\n",
       " \n",
       "        [[ -9.5599586 ,   1.67236397,  14.88963643],\n",
       "         [ -1.77675048,   3.96959366,  -1.45979697],\n",
       "         [  9.60788002,  12.11863339, -14.99421279],\n",
       "         [  1.7288291 , -17.76059094,   1.56437333]],\n",
       " \n",
       "        [[  5.63561615,   6.51593179,  15.67414723],\n",
       "         [  2.46443364,   4.54883307, -62.83720616],\n",
       "         [ 11.02615808,  -5.37788488,  -4.08509065],\n",
       "         [-19.12620769,  -5.68688008,  51.24814955]],\n",
       " \n",
       "        [[-11.32141102, -36.32980774,  29.01025379],\n",
       "         [ 37.65926906,  35.85234975, -33.71711875],\n",
       "         [ 52.44621849,  -5.94744497,  -7.42418945],\n",
       "         [-78.78407618,   6.42490326,  12.13105444]]]),\n",
       " 'stress': array([[ 6.57566943e+01,  1.29291100e+01, -4.82284035e-01,\n",
       "          1.29291098e+01,  1.04993399e+02, -4.84037839e-01,\n",
       "         -4.82284121e-01, -4.84036906e-01, -4.29807312e+00],\n",
       "        [ 1.05365074e+02,  1.37561605e+01,  3.51623924e+00,\n",
       "          1.37561605e+01,  9.30274802e+01,  9.67248676e-02,\n",
       "          3.51624140e+00,  9.67262824e-02, -1.33011718e+00],\n",
       "        [ 1.07821700e+02,  5.09543930e+00,  4.10302005e-01,\n",
       "          5.09543934e+00,  1.11428428e+02,  3.88753688e-01,\n",
       "          4.10301588e-01,  3.88753102e-01, -8.07045791e-01],\n",
       "        [ 1.02887901e+02, -1.02551956e+01, -1.13084878e+00,\n",
       "         -1.02551957e+01,  2.11949992e+02, -2.06746739e-01,\n",
       "         -1.13085014e+00, -2.06745983e-01,  4.96164588e+00],\n",
       "        [-2.09556356e+01, -1.25021412e+01,  2.48080273e+00,\n",
       "         -1.25021411e+01, -4.04310783e+01,  2.24084997e+00,\n",
       "          2.48080011e+00,  2.24084766e+00, -2.21557411e+00]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction using the first 5 data in test dataset\n",
    "\n",
    "input_dict = get_input_dict(test_dataset.take(5))\n",
    "model.predict(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 19:38:55.069516: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: example.tfdnn/assets\n",
      "Network signatures and descriptor are written to example.tfdnn/parameters for LAMMPS simulation.\n"
     ]
    }
   ],
   "source": [
    "# save the trained model\n",
    "\n",
    "descriptor = {'name': 'acsf', \n",
    "              'cutoff': 6.5001,\n",
    "              'etaG2':[0.01,0.025,0.05,0.075,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.8,1,1.5,2,3,5,10], \n",
    "              'etaG4': [0.01], \n",
    "              'zeta': [0.08,0.1,0.15,0.2,0.3,0.35,0.5,0.6,0.8,1.,1.5,2.,3.0,4.,5.5,7.0,10.0,25.0,50.0,100.0],\n",
    "              'lambda': [1.0, -1.0]}\n",
    "\n",
    "save_dir = 'example.tfdnn'\n",
    "network.save(model,save_dir,descriptor=descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['atom_type'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, -1)\n",
      "      name: serving_default_atom_type:0\n",
      "  inputs['center_atom_id'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, -1)\n",
      "      name: serving_default_center_atom_id:0\n",
      "  inputs['dgdr'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, -1, -1, -1)\n",
      "      name: serving_default_dgdr:0\n",
      "  inputs['fingerprints'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, -1, -1)\n",
      "      name: serving_default_fingerprints:0\n",
      "  inputs['neighbor_atom_coord'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, -1, -1, -1)\n",
      "      name: serving_default_neighbor_atom_coord:0\n",
      "  inputs['neighbor_atom_id'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, -1)\n",
      "      name: serving_default_neighbor_atom_id:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['atom_pe'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, -1, 1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "  outputs['force'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, -1, 1, -1)\n",
      "      name: StatefulPartitionedCall:1\n",
      "  outputs['stress'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, -1, 9)\n",
      "      name: StatefulPartitionedCall:2\n",
      "Method name is: tensorflow/serving/predict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the tensorflow signature of the saved model\n",
    "\n",
    "network.print_signature(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network has been inflated! self.built: True\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model for continuous training and prediction\n",
    "\n",
    "imported_model = network.load(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forces are used for training.\n",
      "Stresses are used for training.\n",
      "Scaling factors are computed using training dataset.\n",
      "Training dataset are standardized.\n",
      "Validation dataset are standardized.\n",
      "Training dataset will be shuffled during training.\n",
      "\n",
      "===> Epoch 1/5 - 0.809s/epoch\n",
      "     training_loss    - pe_loss: 7.996 - force_loss: 33.511 - stress_loss: 768.810 - total_loss: 118.388\n",
      "     validation_loss  - pe_loss: 7.985 - force_loss: 27.101 - stress_loss: 633.255 - total_loss: 98.412\n",
      "\n",
      "===> Epoch 2/5 - 0.781s/epoch\n",
      "     training_loss    - pe_loss: 4.084 - force_loss: 19.212 - stress_loss: 357.137 - total_loss: 59.009\n",
      "     validation_loss  - pe_loss: 2.469 - force_loss: 15.713 - stress_loss: 196.805 - total_loss: 37.862\n",
      "\n",
      "===> Epoch 3/5 - 0.799s/epoch\n",
      "     training_loss    - pe_loss: 2.855 - force_loss: 12.243 - stress_loss: 149.484 - total_loss: 30.047\n",
      "     validation_loss  - pe_loss: 1.552 - force_loss: 11.170 - stress_loss: 138.195 - total_loss: 26.541\n",
      "\n",
      "===> Epoch 4/5 - 0.790s/epoch\n",
      "     training_loss    - pe_loss: 1.656 - force_loss: 9.215 - stress_loss: 94.212 - total_loss: 20.292\n",
      "     validation_loss  - pe_loss: 1.275 - force_loss: 8.573 - stress_loss: 68.279 - total_loss: 16.676\n",
      "\n",
      "===> Epoch 5/5 - 0.797s/epoch\n",
      "     training_loss    - pe_loss: 0.924 - force_loss: 7.035 - stress_loss: 77.058 - total_loss: 15.664\n",
      "     validation_loss  - pe_loss: 0.819 - force_loss: 6.876 - stress_loss: 48.661 - total_loss: 12.561\n",
      "\n",
      "End of training, elapsed time:  00:00:03\n"
     ]
    }
   ],
   "source": [
    "# Re-train the model \n",
    "\n",
    "loss_weights = {'pe' : 1, 'force' : 1, 'stress': 0.1}\n",
    "\n",
    "opt = 'Adam'\n",
    "loss_fun = 'rmse'\n",
    "scaling = 'std'\n",
    "\n",
    "model.train(train_dataset, val_dataset, \\\n",
    "            optimizer=opt, \\\n",
    "            loss_fun = loss_fun, \\\n",
    "            batch_size=30, \\\n",
    "            lr=0.02, \\\n",
    "            epochs=5, \\\n",
    "            scaling=scaling, \\\n",
    "            loss_weights=loss_weights, \\\n",
    "            compute_all_loss=True, \\\n",
    "            shuffle=True, \\\n",
    "            append_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss is:\n",
      "        pe_loss:       1.1408e+00\n",
      "     force_loss:       2.0264e+01\n",
      "    stress_loss:       5.7532e+01\n",
      "     total_loss:       2.7158e+01\n",
      "The total loss is computed using the loss weights - pe: 1.00 - force: 1.00 - stress: 0.10\n"
     ]
    }
   ],
   "source": [
    "imported_model.evaluate(test_dataset.take(5),return_prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pe': array([-28.308469  , -30.70238078, -28.37588111, -28.59157203,\n",
       "        -27.23017633]),\n",
       " 'force': array([[[ -4.87540508,  16.20537386,  51.23653551],\n",
       "         [  9.31678774,  -5.65669885, -31.3836977 ],\n",
       "         [-13.68639882,   1.94890128, -20.72748745],\n",
       "         [  9.24501616, -12.49757641,   0.87464961]],\n",
       " \n",
       "        [[ 29.56516981,   5.88600637,  13.2147016 ],\n",
       "         [ 19.65903927,  -3.42711633, -22.04439536],\n",
       "         [-24.48530241,  -4.51321415,  14.96612353],\n",
       "         [-24.73890695,   2.05432393,  -6.13642973]],\n",
       " \n",
       "        [[ -9.5599586 ,   1.67236397,  14.88963643],\n",
       "         [ -1.77675048,   3.96959366,  -1.45979697],\n",
       "         [  9.60788002,  12.11863339, -14.99421279],\n",
       "         [  1.7288291 , -17.76059094,   1.56437333]],\n",
       " \n",
       "        [[  5.63561615,   6.51593179,  15.67414723],\n",
       "         [  2.46443364,   4.54883307, -62.83720616],\n",
       "         [ 11.02615808,  -5.37788488,  -4.08509065],\n",
       "         [-19.12620769,  -5.68688008,  51.24814955]],\n",
       " \n",
       "        [[-11.32141102, -36.32980774,  29.01025379],\n",
       "         [ 37.65926906,  35.85234975, -33.71711875],\n",
       "         [ 52.44621849,  -5.94744497,  -7.42418945],\n",
       "         [-78.78407618,   6.42490326,  12.13105444]]]),\n",
       " 'stress': array([[ 6.57566943e+01,  1.29291100e+01, -4.82284035e-01,\n",
       "          1.29291098e+01,  1.04993399e+02, -4.84037839e-01,\n",
       "         -4.82284121e-01, -4.84036906e-01, -4.29807312e+00],\n",
       "        [ 1.05365074e+02,  1.37561605e+01,  3.51623924e+00,\n",
       "          1.37561605e+01,  9.30274802e+01,  9.67248676e-02,\n",
       "          3.51624140e+00,  9.67262824e-02, -1.33011718e+00],\n",
       "        [ 1.07821700e+02,  5.09543930e+00,  4.10302005e-01,\n",
       "          5.09543934e+00,  1.11428428e+02,  3.88753688e-01,\n",
       "          4.10301588e-01,  3.88753102e-01, -8.07045791e-01],\n",
       "        [ 1.02887901e+02, -1.02551956e+01, -1.13084878e+00,\n",
       "         -1.02551957e+01,  2.11949992e+02, -2.06746739e-01,\n",
       "         -1.13085014e+00, -2.06745983e-01,  4.96164588e+00],\n",
       "        [-2.09556356e+01, -1.25021412e+01,  2.48080273e+00,\n",
       "         -1.25021411e+01, -4.04310783e+01,  2.24084997e+00,\n",
       "          2.48080011e+00,  2.24084766e+00, -2.21557411e+00]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = get_input_dict(test_dataset.take(5))\n",
    "imported_model.predict(input_dict)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
